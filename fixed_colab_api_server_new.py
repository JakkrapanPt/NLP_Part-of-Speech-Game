# Google Colab API Server for Parts of Speech Game
# This file should be run in Google Colab to serve the LLM API

import os
from flask import Flask, request, jsonify
from flask_cors import CORS
import threading
import time
from pyngrok import ngrok
import openai
from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM
import torch
import random

# Initialize Flask app
app = Flask(__name__)
CORS(app)  # Enable CORS for cross-origin requests

# Global variables for models
llm_pipeline = None
tokenizer = None
model = None

# Configuration
CONFIG = {
    'model_name': 'gpt2', 
    'max_length': 100,
    'temperature': 0.7,
    'use_openai': False,  
    'openai_api_key': None  
}

def initialize_model():
    """Initialize the language model"""
    global llm_pipeline, tokenizer, model
    
    print("Initializing language model...")
    
    if CONFIG['use_openai'] and CONFIG['openai_api_key']:
        # Use OpenAI API
        openai.api_key = CONFIG['openai_api_key']
        print("Using OpenAI API")
    else:
        # Use Hugging Face transformers
        try:
            device = 0 if torch.cuda.is_available() else -1
            print(f"Using device: {'GPU' if device == 0 else 'CPU'}")
            
            # Load model and tokenizer
            tokenizer = AutoTokenizer.from_pretrained(CONFIG['model_name'])
            model = AutoModelForCausalLM.from_pretrained(CONFIG['model_name'])
            
            # Set pad token if not set
            if tokenizer.pad_token is None:
                tokenizer.pad_token = tokenizer.eos_token
            
            # Create text generation pipeline with better parameters
            llm_pipeline = pipeline(
                'text-generation',
                model=model,
                tokenizer=tokenizer,
                device=device,
                max_length=CONFIG['max_length'],
                temperature=CONFIG['temperature'],
                do_sample=True,
                top_k=50,
                top_p=0.95,
                no_repeat_ngram_size=2,
                pad_token_id=tokenizer.pad_token_id
            )
            print(f"Model {CONFIG['model_name']} loaded successfully")
            
        except Exception as e:
            print(f"Error loading model: {e}")
            # Fallback to a smaller model
            try:
                print("Attempting to load fallback model...")
                tokenizer = AutoTokenizer.from_pretrained('gpt2')
                model = AutoModelForCausalLM.from_pretrained('gpt2')
                
                if tokenizer.pad_token is None:
                    tokenizer.pad_token = tokenizer.eos_token
                    
                llm_pipeline = pipeline(
                    'text-generation',
                    model=model,
                    tokenizer=tokenizer,
                    device=device if device == -1 else 0,
                    max_length=50,
                    temperature=0.7,
                    do_sample=True,
                    pad_token_id=tokenizer.pad_token_id
                )
                print("Fallback to GPT-2 model successful")
            except Exception as e2:
                print(f"Error loading fallback model: {e2}")
                llm_pipeline = None

# Sample sentences as fallback
FALLBACK_SENTENCES = {
    'en': {
        'easy': [
            "The cat sleeps peacefully.",
            "She runs quickly today.",
            "Birds fly high above.",
            "We eat delicious food.",
            "He plays guitar well.",
            "They dance beautifully together.",
            "I read books daily.",
            "Children laugh happily outside.",
            "Dogs bark loudly sometimes.",
            "Teachers explain concepts clearly."
        ],
        'medium': [
            "The beautiful flowers bloom in spring garden.",
            "Students study hard for their important exams.",
            "My grandmother tells interesting stories every evening.",
            "The chef prepared delicious meals for everyone yesterday.",
            "Our team won the championship after intense practice.",
            "The museum exhibits ancient artifacts from various civilizations.",
            "She completed her project before the strict deadline.",
            "The musician composed beautiful melodies on his piano.",
            "The detective solved the mysterious case last week.",
            "Many tourists visit famous landmarks during summer vacation."
        ],
        'hard': [
            "The magnificent orchestra performed brilliantly at the prestigious concert hall last night.",
            "Scientists carefully analyze complex data to understand mysterious phenomena in deep space.",
            "The experienced journalist documented the extraordinary political developments throughout the turbulent decade.",
            "Environmental researchers discovered unprecedented changes in the ecosystem after extensive fieldwork.",
            "The innovative technology company unveiled revolutionary products during their annual conference yesterday.",
            "Professional athletes demonstrate remarkable discipline and dedication throughout their challenging careers.",
            "The renowned professor published groundbreaking research that transformed theoretical physics fundamentally.",
            "International diplomats negotiated complex agreements between multiple countries during the summit.",
            "Talented architects designed sustainable buildings that harmonize perfectly with natural surroundings.",
            "Medical researchers developed effective treatments for previously incurable diseases after decades of work."
        ]
    },
    'th': {
        'easy': [
            "‡πÅ‡∏°‡∏ß‡∏ô‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏ö‡∏™‡∏ö‡∏≤‡∏¢",
            "‡πÄ‡∏Ç‡∏≤‡∏ß‡∏¥‡πà‡∏á‡πÄ‡∏£‡πá‡∏ß‡∏°‡∏≤‡∏Å",
            "‡∏ô‡∏Å‡∏ö‡∏¥‡∏ô‡∏™‡∏π‡∏á‡∏Ç‡∏∂‡πâ‡∏ô",
            "‡πÄ‡∏£‡∏≤‡∏Å‡∏¥‡∏ô‡∏Ç‡πâ‡∏≤‡∏ß‡∏≠‡∏£‡πà‡∏≠‡∏¢",
            "‡πÄ‡∏ò‡∏≠‡∏≠‡πà‡∏≤‡∏ô‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡πÄ‡∏Å‡πà‡∏á",
            "‡∏â‡∏±‡∏ô‡∏ä‡∏≠‡∏ö‡∏î‡∏π‡∏´‡∏ô‡∏±‡∏á",
            "‡∏û‡∏ß‡∏Å‡πÄ‡∏Ç‡∏≤‡πÄ‡∏•‡πà‡∏ô‡∏î‡∏ô‡∏ï‡∏£‡∏µ",
            "‡∏ô‡πâ‡∏≠‡∏á‡∏£‡πâ‡∏≠‡∏á‡πÄ‡∏û‡∏•‡∏á‡πÑ‡∏û‡πÄ‡∏£‡∏≤‡∏∞",
            "‡∏û‡πà‡∏≠‡∏Ç‡∏±‡∏ö‡∏£‡∏ñ‡πÄ‡∏£‡πá‡∏ß",
            "‡πÅ‡∏°‡πà‡∏ó‡∏≥‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏≠‡∏£‡πà‡∏≠‡∏¢",
            "‡πÄ‡∏î‡πá‡∏Å‡πÜ‡∏ß‡∏¥‡πà‡∏á‡πÄ‡∏•‡πà‡∏ô‡∏™‡∏ô‡∏∏‡∏Å",
            "‡∏Ñ‡∏£‡∏π‡∏™‡∏≠‡∏ô‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡∏î‡∏µ",
            "‡∏´‡∏°‡∏≤‡πÄ‡∏´‡πà‡∏≤‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏î‡∏±‡∏á",
            "‡πÅ‡∏î‡∏î‡∏£‡πâ‡∏≠‡∏ô‡∏°‡∏≤‡∏Å‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ",
            "‡∏ù‡∏ô‡∏ï‡∏Å‡∏´‡∏ô‡∏±‡∏Å‡∏°‡∏≤‡∏Å"
        ],
        'medium': [
            "‡∏ô‡∏±‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏Ç‡∏¢‡∏±‡∏ô‡∏≠‡πà‡∏≤‡∏ô‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏≠‡∏ö",
            "‡∏î‡∏≠‡∏Å‡πÑ‡∏°‡πâ‡∏™‡∏ß‡∏¢‡∏ö‡∏≤‡∏ô‡πÉ‡∏ô‡∏™‡∏ß‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏ö‡πâ‡∏≤‡∏ô",
            "‡∏Ñ‡∏∏‡∏ì‡∏¢‡∏≤‡∏¢‡πÄ‡∏•‡πà‡∏≤‡∏ô‡∏¥‡∏ó‡∏≤‡∏ô‡πÉ‡∏´‡πâ‡∏ü‡∏±‡∏á‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏∑‡∏ô",
            "‡∏û‡∏ß‡∏Å‡πÄ‡∏£‡∏≤‡πÑ‡∏õ‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß‡∏ó‡∏∞‡πÄ‡∏•‡πÉ‡∏ô‡∏ß‡∏±‡∏ô‡∏´‡∏¢‡∏∏‡∏î",
            "‡πÄ‡∏î‡πá‡∏Å‡πÜ‡∏ä‡∏≠‡∏ö‡∏Å‡∏¥‡∏ô‡πÑ‡∏≠‡∏®‡∏Å‡∏£‡∏µ‡∏°‡πÉ‡∏ô‡∏ß‡∏±‡∏ô‡∏£‡πâ‡∏≠‡∏ô",
            "‡∏ô‡∏±‡∏Å‡∏Å‡∏µ‡∏¨‡∏≤‡∏ù‡∏∂‡∏Å‡∏ã‡πâ‡∏≠‡∏°‡∏´‡∏ô‡∏±‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏≤‡∏£‡πÅ‡∏Ç‡πà‡∏á‡∏Ç‡∏±‡∏ô",
            "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏£‡∏π‡∏™‡∏≠‡∏ô‡∏ß‡∏¥‡∏ä‡∏≤‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏™‡∏ô‡∏∏‡∏Å",
            "‡∏ô‡∏±‡∏Å‡∏î‡∏ô‡∏ï‡∏£‡∏µ‡πÄ‡∏•‡πà‡∏ô‡πÄ‡∏û‡∏•‡∏á‡πÑ‡∏û‡πÄ‡∏£‡∏≤‡∏∞‡∏ö‡∏ô‡πÄ‡∏ß‡∏ó‡∏µ",
            "‡∏ä‡∏≤‡∏ß‡∏ô‡∏≤‡∏õ‡∏•‡∏π‡∏Å‡∏Ç‡πâ‡∏≤‡∏ß‡πÉ‡∏ô‡∏§‡∏î‡∏π‡∏ù‡∏ô‡∏ó‡∏∏‡∏Å‡∏õ‡∏µ",
            "‡∏ô‡∏±‡∏Å‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÅ‡∏ï‡πà‡∏á‡∏ô‡∏¥‡∏¢‡∏≤‡∏¢‡∏™‡∏ô‡∏∏‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡πÄ‡∏•‡πà‡∏°",
            "‡∏ä‡πà‡∏≤‡∏á‡∏†‡∏≤‡∏û‡∏ñ‡πà‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡∏™‡∏ß‡∏¢‡πÉ‡∏ô‡∏á‡∏≤‡∏ô‡πÅ‡∏ï‡πà‡∏á‡∏á‡∏≤‡∏ô",
            "‡∏´‡∏°‡∏≠‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏Ñ‡∏ô‡πÑ‡∏Ç‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏≠‡∏≤‡πÉ‡∏à‡πÉ‡∏™‡πà",
            "‡∏û‡πà‡∏≠‡∏Ñ‡πâ‡∏≤‡∏Ç‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡πÉ‡∏ô‡∏ï‡∏•‡∏≤‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡πÄ‡∏ä‡πâ‡∏≤",
            "‡πÄ‡∏î‡πá‡∏Å‡∏ô‡∏±‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ö‡πâ‡∏≤‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à‡∏Å‡πà‡∏≠‡∏ô‡∏ô‡∏≠‡∏ô",
            "‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏´‡∏ô‡∏±‡∏Å‡∏ï‡∏•‡∏≠‡∏î‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå"
        ],
        'hard': [
            "‡∏ô‡∏±‡∏Å‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏õ‡∏£‡∏≤‡∏Å‡∏è‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏•‡∏∂‡∏Å‡∏•‡∏±‡∏ö‡πÉ‡∏ô‡∏≠‡∏ß‡∏Å‡∏≤‡∏®",
            "‡∏ß‡∏á‡∏î‡∏∏‡∏£‡∏¥‡∏¢‡∏≤‡∏á‡∏Ñ‡πå‡∏ä‡∏∑‡πà‡∏≠‡∏î‡∏±‡∏á‡πÅ‡∏™‡∏î‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏¢‡∏≠‡∏î‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏°‡πÉ‡∏ô‡∏´‡∏≠‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏°‡πÉ‡∏´‡∏ç‡πà‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Ñ‡∏∑‡∏ô‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏°‡∏≤",
            "‡∏ô‡∏±‡∏Å‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏õ‡∏¥‡∏î‡∏ï‡∏±‡∏ß‡∏ô‡∏ß‡∏ô‡∏¥‡∏¢‡∏≤‡∏¢‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡∏¥‡∏¢‡∏°‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡πâ‡∏ô‡∏´‡∏•‡∏≤‡∏°‡πÉ‡∏ô‡∏á‡∏≤‡∏ô‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠",
            "‡∏ô‡∏±‡∏Å‡∏Å‡∏µ‡∏¨‡∏≤‡∏ó‡∏µ‡∏°‡∏ä‡∏≤‡∏ï‡∏¥‡∏ù‡∏∂‡∏Å‡∏ã‡πâ‡∏≠‡∏°‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏´‡∏ô‡∏±‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏Ç‡πà‡∏á‡∏Ç‡∏±‡∏ô‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏ô‡∏≤‡∏ô‡∏≤‡∏ä‡∏≤‡∏ï‡∏¥‡πÉ‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤",
            "‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏î‡πâ‡∏≤‡∏ô‡∏™‡∏¥‡πà‡∏á‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏°‡∏•‡∏û‡∏¥‡∏©‡∏ó‡∏≤‡∏á‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡πà‡∏á‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏ï‡πà‡∏≠‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡πÉ‡∏´‡∏ç‡πà",
            "‡∏ô‡∏±‡∏Å‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à‡∏£‡∏∏‡πà‡∏ô‡πÉ‡∏´‡∏°‡πà‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡∏Ñ‡∏ô‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏ß‡∏•‡∏≤‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô",
            "‡∏≠‡∏≤‡∏à‡∏≤‡∏£‡∏¢‡πå‡∏°‡∏´‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢‡∏ô‡∏≥‡πÄ‡∏™‡∏ô‡∏≠‡∏ú‡∏•‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏µ‡∏û‡∏¥‡∏°‡∏û‡πå‡πÉ‡∏ô‡∏ß‡∏≤‡∏£‡∏™‡∏≤‡∏£‡∏ß‡∏¥‡∏ä‡∏≤‡∏Å‡∏≤‡∏£‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏ô‡∏≤‡∏ô‡∏≤‡∏ä‡∏≤‡∏ï‡∏¥",
            "‡∏®‡∏¥‡∏•‡∏õ‡∏¥‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏î‡∏±‡∏á‡∏à‡∏±‡∏î‡∏ô‡∏¥‡∏ó‡∏£‡∏£‡∏®‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏á‡∏≤‡∏ô‡∏®‡∏¥‡∏•‡∏õ‡∏∞‡∏£‡πà‡∏ß‡∏°‡∏™‡∏°‡∏±‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∞‡∏ó‡πâ‡∏≠‡∏ô‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏™‡∏±‡∏á‡∏Ñ‡∏°‡πÉ‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô",
            "‡∏ô‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡∏ó‡∏π‡∏ï‡πÄ‡∏à‡∏£‡∏à‡∏≤‡∏Ç‡πâ‡∏≠‡∏ï‡∏Å‡∏•‡∏á‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏≤‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏™‡πà‡∏á‡∏ú‡∏•‡∏î‡∏µ‡∏ï‡πà‡∏≠‡πÄ‡∏®‡∏£‡∏©‡∏ê‡∏Å‡∏¥‡∏à‡πÉ‡∏ô‡∏†‡∏π‡∏°‡∏¥‡∏†‡∏≤‡∏Ñ",
            "‡∏™‡∏ñ‡∏≤‡∏õ‡∏ô‡∏¥‡∏Å‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏≠‡∏≤‡∏Ñ‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡∏ó‡∏±‡∏ô‡∏™‡∏°‡∏±‡∏¢‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏£‡∏Å‡∏±‡∏ö‡∏™‡∏¥‡πà‡∏á‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°",
            "‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏Ñ‡πâ‡∏ô‡∏û‡∏ö‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏Å‡∏©‡∏≤‡πÇ‡∏£‡∏Ñ‡∏ó‡∏µ‡πà‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏ô‡∏ß‡∏±‡∏ï‡∏Å‡∏£‡∏£‡∏°‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå‡πÅ‡∏ö‡∏ö‡πÉ‡∏´‡∏°‡πà",
            "‡∏ô‡∏±‡∏Å‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏î‡πâ‡∏≤‡∏ô‡∏õ‡∏±‡∏ç‡∏ç‡∏≤‡∏õ‡∏£‡∏∞‡∏î‡∏¥‡∏©‡∏ê‡πå‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏£‡∏∞‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏û‡∏§‡∏ï‡∏¥‡∏Å‡∏£‡∏£‡∏°‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡∏ö‡∏£‡∏¥‡πÇ‡∏†‡∏Ñ‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥",
            "‡∏ú‡∏π‡πâ‡∏Å‡∏≥‡∏Å‡∏±‡∏ö‡∏†‡∏≤‡∏û‡∏¢‡∏ô‡∏ï‡∏£‡πå‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ú‡∏•‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏¢‡∏Å‡∏¢‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡∏Å‡∏ß‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏±‡πà‡∏ß‡πÇ‡∏•‡∏Å",
            "‡∏ô‡∏±‡∏Å‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏Ñ‡πâ‡∏ô‡∏û‡∏ö‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏≠‡∏≤‡∏£‡∏¢‡∏ò‡∏£‡∏£‡∏°‡πÇ‡∏ö‡∏£‡∏≤‡∏ì",
            "‡∏ô‡∏±‡∏Å‡πÄ‡∏®‡∏£‡∏©‡∏ê‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏ï‡∏•‡∏≤‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô‡πÇ‡∏•‡∏Å‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß"
        ]
    }
}

# Track used sentences to avoid repetition
# Using lists instead of sets for better control
USED_SENTENCES = {
    'en': {'easy': [], 'medium': [], 'hard': []},
    'th': {'easy': [], 'medium': [], 'hard': []}
}

# Track last used sentence to avoid immediate repetition
LAST_SENTENCE = {
    'en': {'easy': None, 'medium': None, 'hard': None},
    'th': {'easy': None, 'medium': None, 'hard': None}
}

# English-Thai translation pairs for common words (for simple translations)
TRANSLATION_PAIRS = {
    "cat": "‡πÅ‡∏°‡∏ß",
    "dog": "‡∏´‡∏°‡∏≤",
    "bird": "‡∏ô‡∏Å",
    "run": "‡∏ß‡∏¥‡πà‡∏á",
    "eat": "‡∏Å‡∏¥‡∏ô",
    "sleep": "‡∏ô‡∏≠‡∏ô",
    "read": "‡∏≠‡πà‡∏≤‡∏ô",
    "write": "‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô",
    "book": "‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠",
    "food": "‡∏≠‡∏≤‡∏´‡∏≤‡∏£",
    "house": "‡∏ö‡πâ‡∏≤‡∏ô",
    "school": "‡πÇ‡∏£‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô",
    "teacher": "‡∏Ñ‡∏£‡∏π",
    "student": "‡∏ô‡∏±‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô",
    "friend": "‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô",
    "family": "‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏£‡∏±‡∏ß",
    "water": "‡∏ô‡πâ‡∏≥",
    "sun": "‡∏û‡∏£‡∏∞‡∏≠‡∏≤‡∏ó‡∏¥‡∏ï‡∏¢‡πå",
    "moon": "‡∏û‡∏£‡∏∞‡∏à‡∏±‡∏ô‡∏ó‡∏£‡πå",
    "star": "‡∏î‡∏≤‡∏ß",
    "tree": "‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ",
    "flower": "‡∏î‡∏≠‡∏Å‡πÑ‡∏°‡πâ",
    "beautiful": "‡∏™‡∏ß‡∏¢",
    "happy": "‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡∏Ç",
    "sad": "‡πÄ‡∏®‡∏£‡πâ‡∏≤",
    "big": "‡πÉ‡∏´‡∏ç‡πà",
    "small": "‡πÄ‡∏•‡πá‡∏Å",
    "fast": "‡πÄ‡∏£‡πá‡∏ß",
    "slow": "‡∏ä‡πâ‡∏≤",
    "good": "‡∏î‡∏µ",
    "bad": "‡πÅ‡∏¢‡πà",
    "hot": "‡∏£‡πâ‡∏≠‡∏ô",
    "cold": "‡∏´‡∏ô‡∏≤‡∏ß"
}

@app.route('/health', methods=['GET'])
def health_check():
    """Health check endpoint"""
    return jsonify({
        'status': 'healthy',
        'model_loaded': llm_pipeline is not None or CONFIG['use_openai'],
        'timestamp': time.time()
    })

def is_valid_thai_sentence(text):
    """Check if a text is a valid Thai sentence"""
    if not text or len(text) < 3:  # Too short to be valid
        return False
        
    # Simple check for Thai characters
    thai_chars = 0
    for char in text:
        if '\u0e00' <= char <= '\u0e7f':  # Thai Unicode range
            thai_chars += 1
    return thai_chars > len(text) * 0.5  # At least 50% Thai characters

def simple_translate_to_thai(english_text):
    """Very simple word-by-word translation for testing"""
    words = english_text.lower().translate(str.maketrans('', '', ',.!?;:')).split()
    thai_words = []
    
    for word in words:
        if word in TRANSLATION_PAIRS:
            thai_words.append(TRANSLATION_PAIRS[word])
        else:
            # Skip words we don't know
            continue
    
    # If we couldn't translate anything, return None
    if not thai_words:
        return None
        
    return ' '.join(thai_words)

@app.route('/generate_sentence', methods=['POST'])
def generate_sentence_api():
    """API endpoint to generate sentences"""
    try:
        # Add error handling for JSON parsing
        try:
            data = request.get_json()
            if data is None:
                return jsonify({
                    'success': False,
                    'error': 'Invalid JSON data in request'
                }), 400
        except Exception as e:
            return jsonify({
                'success': False,
                'error': f'Error parsing request data: {str(e)}'
            }), 400
        
        # Extract parameters - only language is needed now
        language = data.get('language', 'en')
        
        # Always generate English sentences first
        english_sentence = None
        
        # Try to generate an English sentence
        if CONFIG['use_openai'] and CONFIG['openai_api_key']:
            try:
                # Use OpenAI API to generate an English sentence
                response = openai.Completion.create(
                    engine="text-davinci-003",
                    prompt="Generate an interesting English sentence:",
                    max_tokens=50,
                    temperature=0.7
                )
                english_sentence = response.choices[0].text.strip()
                method = "openai"
            except Exception as e:
                print(f"OpenAI API error: {e}")
                english_sentence = None
        
        # If OpenAI failed or not available, use Hugging Face
        if english_sentence is None and llm_pipeline is not None:
            try:
                # Generate an English sentence with varying complexity
                prompt = "Write an interesting English sentence:"
                outputs = llm_pipeline(prompt, max_length=100, num_return_sequences=1)
                
                # Extract the generated text
                generated_text = outputs[0]['generated_text']
                
                # Remove the prompt
                if generated_text.startswith(prompt):
                    generated_text = generated_text[len(prompt):].strip()
                
                # Clean up the text
                sentences = generated_text.split('.')
                if sentences and len(sentences) > 0:
                    # Get first non-empty sentence
                    for s in sentences:
                        if s.strip():
                            english_sentence = s.strip() + '.'
                            break
                else:
                    english_sentence = generated_text.strip()
                    if not english_sentence.endswith('.'):
                        english_sentence += '.'
                        
                method = "huggingface"
            except Exception as e:
                print(f"Hugging Face model error: {e}")
                english_sentence = None
        
        # If we still don't have a sentence, use a fallback
        if not english_sentence:
            # Get a random English sentence from our collection
            all_english = []
            for diff in ['easy', 'medium', 'hard']:
                all_english.extend(FALLBACK_SENTENCES['en'][diff])
            
            english_sentence = random.choice(all_english)
            method = "english_fallback"
            
        # Now we have an English sentence, determine its difficulty based on word count
        word_count = len(english_sentence.split())
        
        if word_count <= 6:
            difficulty = 'easy'
        elif word_count >= 15:
            difficulty = 'hard'
        else:
            difficulty = 'medium'
            
        # If the user wants English, we're done
        if language == 'en':
            sentence = english_sentence
        else:
            # For Thai, we need to translate the English sentence
            thai_sentence = None
            
            # Try to translate using the model
            try:
                if llm_pipeline is not None:
                    prompt = f"Translate this English sentence to Thai: '{english_sentence}'"
                    outputs = llm_pipeline(prompt, max_length=150, num_return_sequences=1)
                    
                    # Extract the generated text
                    generated_text = outputs[0]['generated_text']
                    
                    # Remove the prompt
                    if generated_text.startswith(prompt):
                        generated_text = generated_text[len(prompt):].strip()
                    
                    # Extract Thai text - look for Thai characters
                    thai_text = ""
                    in_thai = False
                    for char in generated_text:
                        if '\u0e00' <= char <= '\u0e7f':
                            thai_text += char
                            in_thai = True
                        elif in_thai and (char.isspace() or char in ',.;:!?'):
                            thai_text += char
                    
                    if thai_text.strip():
                        thai_sentence = thai_text.strip()
            except Exception as e:
                print(f"Translation error: {e}")
                thai_sentence = None
                
            # Try simple word-by-word translation as backup
            if not thai_sentence or not is_valid_thai_sentence(thai_sentence):
                simple_thai = simple_translate_to_thai(english_sentence)
                if simple_thai and is_valid_thai_sentence(simple_thai):
                    thai_sentence = simple_thai
                    method = "simple_translation"
            
            # If translation failed, use a fallback Thai sentence
            if not thai_sentence or not is_valid_thai_sentence(thai_sentence):
                # Get a Thai sentence of similar difficulty
                thai_sentences = FALLBACK_SENTENCES['th'][difficulty]
                
                # Get one that hasn't been used recently
                used_list = USED_SENTENCES['th'][difficulty]
                last_used = LAST_SENTENCE['th'][difficulty]
                
                available = [s for s in thai_sentences if s != last_used and s not in used_list]
                if not available:
                    available = [s for s in thai_sentences if s != last_used]
                    if not available:
                        available = thai_sentences
                
                thai_sentence = random.choice(available)
                used_list.append(thai_sentence)
                LAST_SENTENCE['th'][difficulty] = thai_sentence
                
                method = "thai_fallback"
            else:
                method = "translated"
            
            sentence = thai_sentence
        
        # Ensure we have a valid sentence
        if not sentence:
            sentence = "The quick brown fox jumps." if language == 'en' else "‡πÅ‡∏°‡∏ß‡∏î‡∏≥‡∏ß‡∏¥‡πà‡∏á‡πÄ‡∏£‡πá‡∏ß"
            method = "emergency_fallback"
            difficulty = "easy"
        
        # For debugging
        print(f"Generated {language} sentence ({difficulty}): {sentence}")
        print(f"Method: {method}")
            
        return jsonify({
            'success': True,
            'sentence': sentence,
            'language': language,
            'difficulty': difficulty,
            'method': method
        })
        
    except Exception as e:
        print(f"Error in generate_sentence_api: {e}")
        # Return a fallback sentence even on error
        language = request.get_json().get('language', 'en') if request.get_json() else 'en'
        fallback = "The quick brown fox jumps." if language == 'en' else "‡πÅ‡∏°‡∏ß‡∏î‡∏≥‡∏ß‡∏¥‡πà‡∏á‡πÄ‡∏£‡πá‡∏ß"
        
        return jsonify({
            'success': True,  # Return success to prevent app from breaking
            'sentence': fallback,
            'language': language,
            'difficulty': 'easy',
            'method': 'error_fallback',
            'error_info': str(e)
        })

def run_server():
    """Run the Flask server"""
    # Initialize the model
    initialize_model()
    
    # Start the server
    app.run(host='0.0.0.0', port=5000, debug=False, threaded=True)

def setup_ngrok():
    """Setup ngrok tunnel for external access"""
    try:
        # Create tunnel
        public_url = ngrok.connect(5000)
        print(f"\nüåê Public URL: {public_url}")
        print(f"üì± Use this URL in your Streamlit app: {public_url}")
        print(f"üîó API endpoint: {public_url}/generate_sentence")
        
        return public_url
        
    except Exception as e:
        print(f"Error setting up ngrok: {e}")
        return None

if __name__ == '__main__':
    print("üöÄ Starting Parts of Speech Game API Server")
    
    print("üåê Setting up ngrok tunnel...")
    public_url = setup_ngrok()
    
    print("\nüéØ API Endpoints:")
    print("  - POST /generate_sentence - Generate sentences")
    print("  - GET /health - Health check")
    
    print("\nüî• Starting Flask server...")
    
    # Start the server
    try:
        run_server()
    except KeyboardInterrupt:
        print("\nüëã Server stopped")
        ngrok.disconnect(public_url)
        ngrok.kill()
